# Redis LangCache â€” PTâ€‘BR Demo (Gradio UI)

Uma demo 100% prÃ¡tica mostrando **Redis LangCache** + **OpenAI** com **cache semÃ¢ntico** e **escopo por Company / BU / Person**, usando uma **interface Gradio**.

> CÃ³digo principal desta demo: [`main_demo_released.py`](https://github.com/Redislabs-Solution-Architects/redis-langcache-python-example/blob/main/main_demo_released.py)

---

## âœ¨ O que esta demo faz

- **Cache semÃ¢ntico** para respostas de LLMs, reduzindo **latÃªncia** e **custo**.
- **Escopo de reutilizaÃ§Ã£o** por **Company / BU / Person** â€” vocÃª controla o isolamento.
- **DesambiguaÃ§Ã£o por domÃ­nio**: perguntas ambÃ­guas (ex.: â€œcÃ©lulaâ€, â€œredeâ€, â€œbancoâ€) sÃ£o respondidas no **contexto certo**.
- **Identidade**:
  - **Nome** â†’ sem cache (apenas exibiÃ§Ã£o quando perguntado).
  - **Cargo/FunÃ§Ã£o** â†’ armazenado com **chave exata** (`[IDENTITY:ROLE]`) e suporta **â€œsetâ€** via texto (â€œMinha funÃ§Ã£o Ã© â€¦â€).
- **UI de manutenÃ§Ã£o**: botÃµes para **limpar entradas do cache** por escopo (A, B ou A+B). *Nunca apaga o Ã­ndice.*
- **KPIs na tela**: hits, misses, taxa de acerto, tokens estimados e economia.

---

## ğŸ“¦ Estrutura do projeto (mÃ­nima)

```
.
â”œâ”€â”€ main_demo_released.py   # App Gradio (esta demo)
â”œâ”€â”€ requirements.txt        # DependÃªncias Python
â”œâ”€â”€ Dockerfile              # Build da imagem
â”œâ”€â”€ docker-compose.yml      # (exemplo) OrquestraÃ§Ã£o local
â””â”€â”€ .env                    # VariÃ¡veis de ambiente (nÃ£o versionar)
```

> O repositÃ³rio tambÃ©m contÃ©m exemplos adicionais (RAG, atributos etc.). Esta demo usa **`main_demo_released.py`**.

---

## ğŸ” VariÃ¡veis de ambiente

Crie um arquivo `.env` na raiz (ou exporte no ambiente) com:

```env
# OpenAI
OPENAI_API_KEY=sk-proj-<sua-chave>
OPENAI_MODEL=gpt-4o-mini

# LangCache (Redis Cloud)
LANGCACHE_SERVICE_KEY=<sua-service-key>   # ou use LANGCACHE_API_KEY
LANGCACHE_CACHE_ID=<seu-cache-id>
LANGCACHE_BASE_URL=https://gcp-us-east4.langcache.redis.io

# (opcional) Redis local / outros
REDIS_URL=redis://localhost:6379/0

# Embeddings (se usados em exemplos de RAG)
EMBED_MODEL=text-embedding-3-small
EMBED_DIM=1536
```

> **Dica:** `LANGCACHE_API_KEY` e `LANGCACHE_SERVICE_KEY` sÃ£o equivalentes para este app. Use **um** deles.

---

## ğŸš€ Como rodar

### 1) Local (Python)

```bash
python -m venv .venv
source .venv/bin/activate      # Linux/Mac
# .venv\Scripts\activate       # Windows PowerShell
pip install -r requirements.txt

# certifique-se de ter o .env configurado
python main_demo_released.py
```

A UI subirÃ¡ em: **http://localhost:7860**

---

### 2) Docker (imagem pronta)

```bash
docker run -d \
  --name langcache-demo \
  --env-file .env \
  -p 7860:7860 \
  gacerioni/gabs-redis-langcache:1.1.0
```

> Apple Silicon (arm64): se necessÃ¡rio, force `--platform linux/amd64` ao rodar a imagem.

---

### 3) Docker Compose (opcional)

```yaml
# docker-compose.yml
version: "3.9"
services:
  langcache-demo:
    image: gacerioni/gabs-redis-langcache:1.1.0
    # platform: linux/amd64  # descomente em Apple Silicon se precisar
    env_file:
      - .env
    ports:
      - "7860:7860"
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
```

```bash
docker compose up -d
```

---

## ğŸ§‘â€ğŸ’» Como usar a UI

1. Preencha **Company**, **Business Unit** e **Person** para os **CenÃ¡rios A e B**.
2. FaÃ§a perguntas nos dois cenÃ¡rios para ver **cache hit/miss** e **desambiguaÃ§Ã£o por domÃ­nio**.
3. Use os botÃµes **ğŸ§¹ Limpar Cache** para apagar **entradas** por escopo (A, B ou A+B).  
   > **Importante:** a limpeza remove **entradas** do cache **sem apagar o Ã­ndice**.

Exemplos Ãºteis para testar:

- â€œ**Minha funÃ§Ã£o Ã© MÃ©dico**.â€ / â€œ**Minha funÃ§Ã£o Ã© Engenheiro de Software**.â€  
- â€œ**Qual Ã© a minha funÃ§Ã£o na empresa?**â€  
- â€œ**O que Ã© uma cÃ©lula?**â€ (saÃºde vs. software)  
- â€œ**Explique o que Ã© aprendizado de mÃ¡quina**.â€ / â€œ**O que Ã© machine learning?**â€  
- â€œ**Qual Ã© o meu nome?**â€

---

## ğŸ—ï¸ Como funciona (resumo tÃ©cnico)

- **Busca** no LangCache por semelhanÃ§a semÃ¢ntica (ou exata, quando apropriado).  
- **Hit** â†’ responde imediato do cache.  
- **Miss** â†’ consulta OpenAI, **salva resposta neutra** no LangCache e exibe.  
- **Isolamento** por atributos (**company**, **business_unit**, **person**).  
- **Perguntas ambÃ­guas** â†’ reescritas internamente para incluir â€œ(no contexto de â€¦)â€ com base no domÃ­nio inferido.

---

## ğŸ§ª CI/CD (opcional)

Se quiser automatizar build e push para Docker Hub + release por tag:
- GitHub Actions com workflow de **build multiâ€‘arch** e **release ao criar `vX.Y.Z`**.
- Secrets necessÃ¡rios no repositÃ³rio:
  - `DOCKERHUB_USERNAME`
  - `DOCKERHUB_TOKEN` (PAT)
  - (`GITHUB_TOKEN` jÃ¡ Ã© fornecido pelo Actions)

> O pipeline compÃµe tags automaticamente (`latest`, `sha`, `branch`, `semver`).

---

## ğŸ”— Links Ãºteis

- **Redis LangCache (docs):** https://redis.io/docs/latest/solutions/semantic-caching/langcache/  
- **Redis (site):** https://redis.io/  
- **LinkedIn (Gabriel Cerioni):** https://www.linkedin.com/in/gabrielcerioni/

---

## ğŸ“ LicenÃ§a

MIT â€” use Ã  vontade.
